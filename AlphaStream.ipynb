{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "30ab0577-f328-47ec-a6ee-c24cc9123798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from itertools import product\n",
    "import datetime\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "# import nbconvert\n",
    "\n",
    "# !jupyter nbconvert --to script AlphaStream.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65550a0e-a33b-4bd6-b95e-ffa8931bdfa7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helper Function: Protein-Sequence request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbfe13b5-2c42-4458-b858-49d2dd49cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that takes the name of a protein as a *string* and gives back the aminoacid sequence through UniProts API\n",
    "\"\"\"\n",
    "\n",
    "def get_uniprot_sequence(protein_name, taxon_id=\"559292\"):\n",
    "    url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    query = f'gene_exact:{protein_name} AND organism_id:{taxon_id}'\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"fasta\", # Wir wollen fasta weil es nices standard-format ist aus dem wir die info gut auslesen koennen\n",
    "        \"size\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200 and response.text.startswith(\">\"): # check rightigen status-code und ob fasta text\n",
    "        lines = response.text.splitlines()\n",
    "        sequence = \"\".join(lines[1:]) # Nur die Sequenz rausholen und in einen string formattieren\n",
    "        return sequence\n",
    "    else:\n",
    "        raise ValueError(f\"No sequence found or request failed for {protein_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a930a48-b8fa-4931-a0b1-21e9e0401c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "#get_uniprot_sequence(\"YB022C\") # is equal to get_uniprot_sequence(\"Pim1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd007239-f1f6-4f12-9ab7-664cae13e50a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helper Function: Jason-Job-File creation\n",
    "\n",
    "Noting right here, that these don't open a json-file just yet, they only return a job string in json format together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbd7758a-df31-4c0b-b418-3a527fd23c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Die Funktion soll dem modularem Aufbau von AlphaStream helfen - es ist eine unterfunktion von create_af3_job und kommt \n",
    "zu Nutzen in den compound_job Funktionen.\n",
    "Input: \n",
    "protein_name : str\n",
    "count : int\n",
    "template : boolean\n",
    "\"\"\"\n",
    "def additional_sequence_json(protein_name, count = 1, template = True):\n",
    "    if len(protein_name) == 0:\n",
    "        raise ValueError(\"Enter a protein (or its sequence) to continue\")\n",
    "    if not isinstance(count, int) or count < 1:\n",
    "        raise ValueError(f\"count for {protein_name} must be a positive integer\")\n",
    "    if not isinstance(template, bool):\n",
    "        raise ValueError(f\"template parameter for {protein_name} must be a boolean\")\n",
    "\n",
    "    if len(protein_name) <= 15: \n",
    "        sequence = get_uniprot_sequence(protein_name)\n",
    "    else: \n",
    "        sequence = protein_name.upper()\n",
    "    \n",
    "    the_additional_sequence = {\"proteinChain\" : {\n",
    "        \"sequence\" : sequence, \n",
    "        \"count\" : count, \n",
    "        \"usesStructureTemplate\" : template}\n",
    "                          }\n",
    "    return the_additional_sequence, len(sequence)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function acts as a helper function in future functions.\n",
    "It returns a json-File in accordance to AlphaFold Server prerequisites.\n",
    "Input :\n",
    "protein_name : one or multiple str\n",
    "count : int or list of ints (MUST be length of *protein_name), or if int and multiple proteins -> int is used for all proteins\n",
    "template : boolean\n",
    "name_prefix : str\n",
    "\"\"\"\n",
    "def create_af3_job(*protein_name, count = 1, template = True, name_prefix=\"af3_job\"): \n",
    "    if len(protein_name) > 1:\n",
    "        if isinstance(count, int):\n",
    "            count = [count] * len(protein_name)\n",
    "        elif len(protein_name) != len(count):\n",
    "            raise ValueError(\"Amount of Proteins must be equal to length of count parameter\") \n",
    "\n",
    "    # I need to make sure the name can be inputted by the user, in case the protein_name is a sequence. WHat happens in split, what happens in ace and in rico? \n",
    "    #OK - thats an alternative, I will make it be the first 6 letters of the protein sequence, thats a 1/16384 chance of being the same as another protein           \n",
    "    defined_protein_name = [p[:7] if len(p) > 15 else p for p in protein_name]\n",
    "    job = {\n",
    "        \"name\": f\"{name_prefix}_{'_and_'.join(defined_protein_name)}\",\n",
    "        \"version\": 1,\n",
    "        \"dialect\": \"alphafoldserver\",\n",
    "        \"sequences\": []\n",
    "    }\n",
    "    tokens = 0\n",
    "    for i, p_name in enumerate(protein_name):\n",
    "        actual_count = count[i] if isinstance(count, list) else count\n",
    "        json_seq, seq_len = additional_sequence_json(p_name, count = actual_count, template = template)\n",
    "        job[\"sequences\"].append(json_seq) #wie ist es mit count und template?\n",
    "        tokens += actual_count*seq_len\n",
    "    \n",
    "    if tokens > 5120:\n",
    "        raise ValueError(f\"The Job for {name_prefix}_{'_and_'.join(defined_protein_name)} uses more than 5120 tokens - the compound of {list(zip(defined_protein_name, count))} is too big.\")\n",
    "    return job\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0485760b-b2a0-4732-907e-0ee3d96b5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "#create_af3_job(\"Pim1\", \"Pim1\", count = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb2980-16be-4315-aa57-3b2add77a3fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146093a1-7224-4cce-be6d-dbe37f04e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Single Protein Inference Tasker: split\n",
    "\n",
    "Function that takes one to multiple protein names as strings and makes a list of Jason-Jobs out of it.\n",
    "The Output is a Json-File for AlphaFold in list-style, so each protein gets own prediction.\n",
    "You can add a *list* of counts to change the count for every protein\n",
    "Input:\n",
    "protein_names : one or multiple str\n",
    "count : int OR list, order must be in accordance to protein name order\n",
    "template : boolean\n",
    "name_prefix : str\n",
    "file_name : str\n",
    "\"\"\"\n",
    "\n",
    "def split(*protein_names, count = 1, template=True, file_name = \"\", name_prefix=\"af3_job\"):\n",
    "\n",
    "    if len(protein_names) > 1:\n",
    "        if isinstance(count, int):\n",
    "            count = [count] * len(protein_names)\n",
    "        elif len(protein_names) != len(count):\n",
    "            raise ValueError(\"Amount of Proteins must be equal to length of count parameter\")\n",
    "    if len(protein_names) == 0:\n",
    "        raise ValueError(\"Enter a protein (or its sequence) to continue\")\n",
    "    if len(protein_names) == 1 and not isinstance(count, int):\n",
    "        raise ValueError(\"Amount of Proteins must be equal to length of count parameter\")\n",
    "\n",
    "    jobs = []\n",
    "\n",
    "    for i, protein_name in enumerate(protein_names):\n",
    "        actual_count = count[i] if isinstance(count, list) else count\n",
    "        job = create_af3_job(protein_name, count = actual_count, template = template, name_prefix = name_prefix)\n",
    "        jobs.append(job)\n",
    "        \n",
    "    x = datetime.datetime.now()\n",
    "\n",
    "    defined_protein_names = [p[:7] if len(p) > 15 else p for p in protein_names]\n",
    "    \n",
    "    if len(file_name) == 0:\n",
    "        with open(f\"{'_and_'.join(defined_protein_names)}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "            json.dump(jobs, f, indent=2)\n",
    "    else:\n",
    "        with open(f\"{file_name}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "            json.dump(jobs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa24bb1-321f-47e6-90c1-a6037ec98f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split(\"Pim1\", \"MNQLGALAQVSRFTQNFSMENIKSEFQSLQSKLATLRTPQEFFNFKKISKPQNFGEVQSRVAYNLKYFSSNYGLIIGCLSIYTLLTNLLLLFVIVLVVAGIVGINKLKGEELVTPFGSFKTNQLYTGLVCVAVPIGFLASPISTLLWLIGASAVSVFGHASLMEKPIETVFDEETV\", count = 3, file_name = \"HiThere\")\n",
    "# or more - Syntax Okay?\n",
    "#split(\"SomeFakeProtein\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50e144-d191-428d-996c-2cba827a5b30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ace Function\n",
    "Be minutious with your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec892821-90b7-487b-9142-337a11b38f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregate of Compound Entities: ace\n",
    "\n",
    "Function that takes one or multiple *dictionaries* with protein names and their respective count.\n",
    "spits out a json-list with as many jobs as there are dictionaries, and this time\n",
    "every job can entail multiple proteins at the same time!\n",
    "Input :\n",
    "protein_compounds : one or multiple dictionaries:\n",
    "    key : str, the protein name\n",
    "    value : int, is count\n",
    "template : boolean\n",
    "name_prefix :  str\n",
    "\"\"\"\n",
    "\n",
    "def ace(*protein_compounds, template = True, name_prefix = \"ace\", file_name = \"\", name = \"\", ashelper = False): # protein_compounds are dictionaries\n",
    "\n",
    "    jobs = []\n",
    "    name = name\n",
    "\n",
    "    if len(protein_compounds) == 0 or not protein_compounds:\n",
    "        raise ValueError(\"Enter protein compounds to continue\")\n",
    "\n",
    "    for i, protein_compound in enumerate(protein_compounds):\n",
    "        if len(protein_compound) == 0:\n",
    "            raise ValueError(\"Don't enter empty dictionaries into ace\")\n",
    "        job = create_af3_job(*protein_compound.keys(), count = list(protein_compound.values()), template = template, name_prefix = f\"{name_prefix}{i+1}\")\n",
    "        jobs.append(job)\n",
    "        defined_names = [p[:7] if len(p) > 12 else p for p in protein_compound.keys()]\n",
    "        if not ashelper:\n",
    "            if i+1 < len(protein_compounds):\n",
    "                name += \"-\".join(defined_names) + \"_and_\"\n",
    "            else:\n",
    "                name += \"-\".join(defined_names)\n",
    "        \n",
    "\n",
    "    x = datetime.datetime.now()\n",
    "\n",
    "    \n",
    "    if len(file_name) == 0:\n",
    "        with open(f\"{\"ace_for_\" if not ashelper else \"\"}{name}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "            json.dump(jobs, f, indent=2)\n",
    "    else:\n",
    "         with open(f\"{file_name}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "            json.dump(jobs, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26c99c3b-564a-4d4e-8990-8775b36dc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ace({\"Pim1\" : 1, \"YBL022C\": 22}, {\"mam33\" : 4, \"Pim1\" : 1}, file_name=\"Ace\") # Syntax zu schwierig?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c7d8f-c107-47a3-b092-7f7ba1b4d187",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helper Function: Cartesian-Product for protein ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc067ce-805e-4d66-b029-17d960380331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that takes one single dictionary with protein names and their respective count, but this time,\n",
    "the count can be a range.\n",
    "It spits out a list of dictionaries with all possible combinations of the given ranges.\n",
    "Its output it supposed to work as an input for the compound function: it's a *list*\n",
    "Input :\n",
    "protein_counts : dictionary:\n",
    "    key : str, protein name\n",
    "    value : int or range, the counts\n",
    "\"\"\"\n",
    "\n",
    "# CHATGPT FOR THE WIN - this gives back a list with dictionaries in all combinations of the given ranges\n",
    "\n",
    "def combine_count_ranges(protein_counts):\n",
    "    # Step 1: Normalize all values to lists\n",
    "    normalized = {k: (v if isinstance(v, range) or isinstance(v, list) else [v]) for k, v in protein_counts.items()}\n",
    "\n",
    "    # Step 2: Separate keys by how many values they have\n",
    "    multi_keys = [k for k, v in normalized.items() if len(v) > 1]\n",
    "    fixed_keys = {k: v[0] for k, v in normalized.items() if len(v) == 1}\n",
    "\n",
    "    # Step 3: Create product of variable value combinations\n",
    "    combinations = product(*(normalized[k] for k in multi_keys))\n",
    "\n",
    "    # Step 4: Rebuild job dicts\n",
    "    job_inputs = []\n",
    "    for combo in combinations:\n",
    "        job = {**fixed_keys}\n",
    "        job.update(dict(zip(multi_keys, combo)))\n",
    "        job_inputs.append(job)\n",
    "\n",
    "    return job_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb487871-370e-45e7-8c3a-e4cd9743389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does its input look like: dictionaries with ranges\n",
    "\n",
    "# input_dict = {\n",
    "#     \"Pim1\": range(2,7),\n",
    "#     \"Fcyx\": range(4, 9),\n",
    "#     \"Mrx6\": range(3,7)\n",
    "# }\n",
    "\n",
    "# tryout = combine_count_ranges(input_dict)\n",
    "# len(tryout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415636e-379e-41dd-a3d0-b71697c67e18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Rico Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aaec6f4-0875-4dc8-a140-b62321e459e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run Iterative Combination Operation: rico\n",
    "\n",
    "This is an alternative to the previous compound function.\n",
    "Function that takes *one single dictionary* with protein names and their respective count/ranges.\n",
    "It uses the combine_count_ranges() function and then \n",
    "spits out a json-list with as many jobs as there are dictionaries (the output of combine function)\n",
    "Input :\n",
    "range_dictionary : same as for combine_count_ranges\n",
    "template: boolean\n",
    "name_prefix : str\n",
    "\"\"\"\n",
    "\n",
    "def rico(range_dictionary, template = True, name_prefix = \"rico\", file_name = \"\"):\n",
    "\n",
    "    if len(range_dictionary) == 0:\n",
    "        raise ValueError(\"Enter a dictionary with proteins as keys and their ranges as values to continue\")\n",
    "    for key, val in range_dictionary.items():\n",
    "        if not isinstance(val, range):\n",
    "            raise TypeError(f\"Expected a range for '{key}', got {type(val).__name__}.\")\n",
    "        if len(val) == 0:\n",
    "            raise ValueError(f\"Range for '{key}' is empty. Enter a range and don't forget that the last number isnt included\")\n",
    "\n",
    "    protein_compounds = combine_count_ranges(range_dictionary)\n",
    "    defined_name = [p[:7] if len(p) > 12 else p for p in range_dictionary.keys()]\n",
    "    name = \"rico_for_\" + \"_and_\".join(defined_name)\n",
    "    ace(*protein_compounds, template = template, name_prefix = name_prefix, file_name = file_name, name = name, ashelper = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a97ed47-79a9-49e4-99c3-813e598e583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rico(\n",
    "#     {\n",
    "#     \"MNQLGALAQVSRFTQNFSMENIKSEFQSLQSKLATLRTPQEFFNFKKISKPQNFGEVQSRVAYNLKYFSSNYGLIIGCLSIYTLLTNLLLLFVIVLVVAGIVGINKLKGEELVTPFGSFKTNQLYTGLVCVAVPIGFLASPISTLLWLIGASAVSVFGHASLMEKPIETVFDEETV\": range(1,3),\n",
    "#     \"Fcyx\": range(1, 3)\n",
    "# }, file_name=\"RICO\")\n",
    "# rico({\"Pim1\":[1,2], \"Pim1\" : [2,3]})\n",
    "# rico({\n",
    "#     \"MNQLGALAQVSRFTQNFSMENIKSEFQSLQSKLATLRTPQEFFNFKKISKPQNFGEVQSRVAYNLKYFSSNYGLIIGCLSIYTLLTNLLLLFVIVLVVAGIVGINKLKGEELVTPFGSFKTNQLYTGLVCVAVPIGFLASPISTLLWLIGASAVSVFGHASLMEKPIETVFDEETV\": range(50,53),\n",
    "#     \"Fcyx\": range(1, 4),\n",
    "#     \"Mrx6\": range(1,4)\n",
    "# }, file_name=\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d68e8-daea-445c-a5fb-ffd1227235f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pair Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "31b88098-ac01-4bd9-865d-75fb4a3ec108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(pairsubjects, *pairobjects, count = 0, file_name = \"\", name_prefix = \"pairing\"):\n",
    "    if not isinstance(pairsubjects, list):\n",
    "        raise ValueError(\"The first input (pairsubjects) needs to be a list (format: []) with one or more protein names or sequences\")\n",
    "    if len(pairsubjects) == 0:\n",
    "        raise ValueError(\"Enter a non-empty list for parameter: pairsubjects\")\n",
    "    if len(pairobjects) == 0:\n",
    "        raise ValueError(\"Enter parameter: pairsubjects as list with strings (format = ['Protein1', 'Protein2']) AND parameter: pairobjects as strings (format example = 'Protein3', 'Protein4')\")\n",
    "    if count == 0:\n",
    "        count = [1] * len(pairobjects)\n",
    "    else:\n",
    "        if not isinstance(count, list):\n",
    "            raise ValueError(\"Count must be a list (format = [])\")\n",
    "        if len(count) != len(pairobjects):\n",
    "            raise ValueError(\"Count must be a list (format = []) with the same amount of inputs as your pairobjects\")\n",
    "\n",
    "    defined_name = [p[:7] if len(p) > 15 else p for p in pairsubjects]\n",
    "    jobs = []\n",
    "    job_template = create_af3_job(*pairsubjects)\n",
    "    tokens = 0\n",
    "    for i, p in enumerate(pairobjects):\n",
    "        add_protein = additional_sequence_json(p, count[i])[0]\n",
    "        paired_job = copy.deepcopy(job_template)\n",
    "        paired_job[\"sequences\"].append(add_protein)\n",
    "        paired_job[\"name\"] = f\"{name_prefix + str(i+1)}_{\"_and_\".join(defined_name)}\"\n",
    "        for j, seq in enumerate(paired_job[\"sequences\"]):\n",
    "            tokens += len(seq[\"proteinChain\"][\"sequence\"]) * seq[\"proteinChain\"][\"count\"]\n",
    "        if tokens > 5120:\n",
    "            raise ValueError(f\"The job for pairing {'_and_'.join(defined_name)} with {count[i]} {p[:7] if len(p) > 15 else p} uses more than 5120 tokens.\")\n",
    "        else:\n",
    "            tokens = 0\n",
    "        jobs.append(paired_job)\n",
    "    \n",
    "\n",
    "    x = datetime.datetime.now()\n",
    "    if len(file_name) == 0:\n",
    "        with open(f\"pair_{'_and_'.join(defined_name)}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "            json.dump(jobs, f, indent=2)\n",
    "    else:\n",
    "        with open(f\"{file_name}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "            json.dump(jobs, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5702b-10d5-4b7f-b1db-69a9cc622473",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f98e9ac7-9d66-47ef-9e01-1d06721c6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def search(parent_folder: str) -> pd.DataFrame:\n",
    "    results = []\n",
    "    # List all subfolders in the parent_folder\n",
    "    for subfolder in os.listdir(parent_folder):\n",
    "        subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "        # Find all summary_confidences JSON files\n",
    "        pattern = os.path.join(subfolder_path, \"fold_*_summary_confidences_*.json\")\n",
    "        files = glob.glob(pattern)\n",
    "        best = None\n",
    "        for f in files:\n",
    "            with open(f, \"r\") as fh:\n",
    "                data = json.load(fh)\n",
    "            score = data.get(\"ranking_score\", float('-inf'))\n",
    "            if best is None or score > best[\"ranking_score\"]:\n",
    "                best = {\n",
    "                    \"folder\": subfolder,\n",
    "                    \"iptm\": data.get(\"iptm\"),\n",
    "                    \"ptm\": data.get(\"ptm\"),\n",
    "                    \"ranking_score\": score\n",
    "                }\n",
    "        # Add protein counts from job_request.json\n",
    "        job_request_path = os.path.join(subfolder_path, \"fold_\" + subfolder + \"_job_request.json\")\n",
    "        if os.path.exists(job_request_path):\n",
    "            with open(job_request_path, \"r\") as fh:\n",
    "                job_data = json.load(fh)\n",
    "            # job_data might be a list or dict, handle both\n",
    "            if isinstance(job_data, list):\n",
    "                job_data = job_data[0]\n",
    "            for seq in job_data.get(\"sequences\", []):\n",
    "                sequence = seq[\"proteinChain\"][\"sequence\"]\n",
    "                count = seq[\"proteinChain\"][\"count\"]\n",
    "                col_name = sequence[:7]\n",
    "                best[col_name] = count\n",
    "        if best:\n",
    "            results.append(best)\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values(\"ranking_score\", ascending=False).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d5e015bf-2654-4b79-9e18-65296f684b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search(\"folds_2025_06_18_08_59\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399ae61-a634-4621-9745-3416a33931c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Zusammenfassung und tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8e41ff3-d9ce-4422-b8c9-5cd650c4a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Sequence *helper function*\n",
    "# get_uniprot_sequence() # Try mistake\n",
    "\n",
    "# # Get Protein Jobs\n",
    "# proteins_to_af3_job()\n",
    "# count_proteins_to_af3_job()\n",
    "\n",
    "# # Compound jobs\n",
    "# single_compounds_af3({\"Pim1\" : 1, \"fcyx\": 2}, {\"mam33\" : 4, \"ATP11\" : 1})\n",
    "\n",
    "# # Combine Ranges *helper function*\n",
    "# input_dict = {}\n",
    "# combine_count_ranges(input_dict)\n",
    "\n",
    "# # better compound job\n",
    "# iterative_compound_af3(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc03558e-0cf2-4eca-9ceb-bd781eda1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create ligand, ion implementation, not that urgent\n",
    "# need to mnake code accessible to osmanlab, urgent, but these steps are necessarz first:\n",
    "# have functional code ready and then put it on the v0 website - question, can I access and work on the website easily?\n",
    "# - update: they use jupyter lab as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddd38364-0b33-4b07-a522-9baa55236438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Edge case tests for AlphaStream functions: split, ace, and rico\n",
    "# \"\"\"\n",
    "\n",
    "# # SPLIT FUNCTION EDGE CASES TO TEST\n",
    "\n",
    "# def test_split_edge_cases():\n",
    "#     \"\"\"Test cases for the split function\"\"\"\n",
    "    \n",
    "#     print(\"=== SPLIT FUNCTION EDGE CASES ===\\n\")\n",
    "    \n",
    "#     # 1. Empty protein names\n",
    "#     try:\n",
    "#         split(\"\")  # Empty string\n",
    "#         print(\"❌ ISSUE: Empty string should raise ValueError\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Empty string handled correctly:\", e)\n",
    "    \n",
    "#     # 2. None values\n",
    "#     try:\n",
    "#         split(None)  # None value\n",
    "#         print(\"❌ ISSUE: None should raise error\")\n",
    "#     except (ValueError, TypeError) as e:\n",
    "#         print(\"✅ None value handled correctly:\", e)\n",
    "    \n",
    "#     # 3. Count edge cases\n",
    "#     try:\n",
    "#         split(\"Pim1\", count=0)  # Zero count\n",
    "#         print(\"❌ ISSUE: Zero count should be invalid\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Zero count handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         split(\"Pim1\", count=-1)  # Negative count\n",
    "#         print(\"❌ ISSUE: Negative count should be invalid\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Negative count handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         split(\"Pim1\", count=\"five\")  # String count\n",
    "#         print(\"❌ ISSUE: String count should be invalid\")\n",
    "#     except (ValueError, TypeError) as e:\n",
    "#         print(\"✅ String count handled correctly:\", e)\n",
    "    \n",
    "#     # 4. Count list mismatches\n",
    "#     try:\n",
    "#         split(\"Pim1\", \"Act1\", count=[1])  # Too few counts\n",
    "#         print(\"❌ ISSUE: Count list mismatch should raise error\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Count list mismatch handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         split(\"Pim1\", count=[1, 2])  # Too many counts for single protein\n",
    "#         print(\"❌ ISSUE: Too many counts should raise error\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Too many counts handled correctly:\", e)\n",
    "    \n",
    "#     # 5. Very long sequences (edge case for naming)\n",
    "#     very_long_seq = \"M\" * 1000\n",
    "#     try:\n",
    "#         split(very_long_seq)\n",
    "#         print(\"✅ Very long sequence handled (check file naming)\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Very long sequence failed:\", e)\n",
    "    \n",
    "#     # 6. Special characters in file_name\n",
    "#     try:\n",
    "#         split(\"Pim1\", file_name=\"test/file\")  # Path separators\n",
    "#         print(\"⚠️  File name with path separators - check if valid\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Special characters in filename failed:\", e)\n",
    "\n",
    "# # ACE FUNCTION EDGE CASES TO TEST\n",
    "\n",
    "# def test_ace_edge_cases():\n",
    "#     \"\"\"Test cases for the ace function\"\"\"\n",
    "    \n",
    "#     print(\"\\n=== ACE FUNCTION EDGE CASES ===\\n\")\n",
    "    \n",
    "#     # 1. Empty dictionary\n",
    "#     try:\n",
    "#         ace({})  # Empty dict\n",
    "#         print(\"❌ ISSUE: Empty dict should be handled\")\n",
    "#     except (ValueError, KeyError) as e:\n",
    "#         print(\"✅ Empty dict handled correctly:\", e)\n",
    "    \n",
    "#     # 2. Dictionary with empty protein names\n",
    "#     try:\n",
    "#         ace({\"\": 1})  # Empty protein name as key\n",
    "#         print(\"❌ ISSUE: Empty protein name should raise error\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Empty protein name handled correctly:\", e)\n",
    "    \n",
    "#     # 3. Dictionary with invalid counts\n",
    "#     try:\n",
    "#         ace({\"Pim1\": 0})  # Zero count\n",
    "#         print(\"❌ ISSUE: Zero count should be invalid\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Zero count in ace handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         ace({\"Pim1\": -1})  # Negative count\n",
    "#         print(\"❌ ISSUE: Negative count should be invalid\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Negative count in ace handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         ace({\"Pim1\": \"two\"})  # String count\n",
    "#         print(\"❌ ISSUE: String count should be invalid\")\n",
    "#     except (ValueError, TypeError) as e:\n",
    "#         print(\"✅ String count in ace handled correctly:\", e)\n",
    "    \n",
    "#     # 4. None as dictionary key or value\n",
    "#     try:\n",
    "#         ace({None: 1})  # None as key\n",
    "#         print(\"❌ ISSUE: None as key should be invalid\")\n",
    "#     except (ValueError, TypeError) as e:\n",
    "#         print(\"✅ None as key handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         ace({\"Pim1\": None})  # None as value\n",
    "#         print(\"❌ ISSUE: None as value should be invalid\")\n",
    "#     except (ValueError, TypeError) as e:\n",
    "#         print(\"✅ None as value handled correctly:\", e)\n",
    "    \n",
    "#     # 5. Very large compound (memory/performance test)\n",
    "#     large_compound = {\"Pim1\": 1 for i in range(100)}\n",
    "#     try:\n",
    "#         ace(large_compound, file_name=\"large_test\")\n",
    "#         print(\"✅ Large compound handled (check performance)\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Large compound failed:\", e)\n",
    "\n",
    "# # RICO FUNCTION EDGE CASES TO TEST\n",
    "\n",
    "# def test_rico_edge_cases():\n",
    "#     \"\"\"Test cases for the rico function\"\"\"\n",
    "    \n",
    "#     print(\"\\n=== RICO FUNCTION EDGE CASES ===\\n\")\n",
    "    \n",
    "#     # 1. Empty dictionary\n",
    "#     try:\n",
    "#         rico({})  # Empty dict\n",
    "#         print(\"❌ ISSUE: Empty dict should raise ValueError\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Empty dict handled correctly:\", e)\n",
    "    \n",
    "#     # 2. Non-range values\n",
    "#     try:\n",
    "#         rico({\"Pim1\": 5})  # Integer instead of range\n",
    "#         print(\"❌ ISSUE: Non-range should raise TypeError\")\n",
    "#     except TypeError as e:\n",
    "#         print(\"✅ Non-range value handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         rico({\"Pim1\": [1, 2, 3]})  # List instead of range\n",
    "#         print(\"❌ ISSUE: List should raise TypeError\")\n",
    "#     except TypeError as e:\n",
    "#         print(\"✅ List value handled correctly:\", e)\n",
    "    \n",
    "#     # 3. Empty ranges\n",
    "#     try:\n",
    "#         rico({\"Pim1\": range(5, 5)})  # Empty range\n",
    "#         print(\"❌ ISSUE: Empty range should raise ValueError\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Empty range handled correctly:\", e)\n",
    "    \n",
    "#     try:\n",
    "#         rico({\"Pim1\": range(5, 3)})  # Backwards range\n",
    "#         print(\"❌ ISSUE: Backwards range should raise ValueError\")\n",
    "#     except ValueError as e:\n",
    "#         print(\"✅ Backwards range handled correctly:\", e)\n",
    "    \n",
    "#     # 4. Negative ranges\n",
    "#     try:\n",
    "#         rico({\"Pim1\": range(-2, 0)})  # Negative range\n",
    "#         print(\"⚠️  Negative range - should this be allowed?\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Negative range failed:\", e)\n",
    "    \n",
    "#     # 5. Very large ranges (performance test)\n",
    "#     try:\n",
    "#         rico({\"Pim1\": range(1, 1000)})  # Large range\n",
    "#         print(\"⚠️  Large range - this will create 999 jobs! Memory/time concern\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Large range failed:\", e)\n",
    "    \n",
    "#     # 6. Multiple large ranges (exponential explosion)\n",
    "#     try:\n",
    "#         rico({\"Pim1\": range(1, 10), \"Act1\": range(1, 10)})  # 9x9=81 combinations\n",
    "#         print(\"⚠️  Multiple ranges - creates 81 jobs, check if intentional\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Multiple ranges failed:\", e)\n",
    "\n",
    "# # ADDITIONAL CROSS-FUNCTION EDGE CASES\n",
    "\n",
    "# def test_general_edge_cases():\n",
    "#     \"\"\"Test cases that affect multiple functions\"\"\"\n",
    "    \n",
    "#     print(\"\\n=== GENERAL EDGE CASES ===\\n\")\n",
    "    \n",
    "#     # 1. Unicode/special characters in protein names\n",
    "#     try:\n",
    "#         split(\"Pim1α\")  # Greek letter\n",
    "#         print(\"✅ Unicode characters handled\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Unicode failed:\", e)\n",
    "    \n",
    "#     # 2. Very long protein names (affects file naming)\n",
    "#     long_name = \"VeryLongProteinNameThatExceedsNormalLimits\" * 3\n",
    "#     try:\n",
    "#         split(long_name[:50])  # Truncate to reasonable length\n",
    "#         print(\"✅ Long protein names handled\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Long protein names failed:\", e)\n",
    "    \n",
    "#     # 3. Template parameter edge cases\n",
    "#     try:\n",
    "#         split(\"Pim1\", template=\"yes\")  # String instead of bool\n",
    "#         print(\"❌ ISSUE: Non-boolean template should raise error\")\n",
    "#     except (ValueError, TypeError) as e:\n",
    "#         print(\"✅ Non-boolean template handled correctly:\", e)\n",
    "    \n",
    "#     # 4. File system limitations\n",
    "#     try:\n",
    "#         split(\"Pim1\", file_name=\"a\" * 255)  # Very long filename\n",
    "#         print(\"⚠️  Very long filename - OS may reject\")\n",
    "#     except Exception as e:\n",
    "#         print(\"❌ Long filename failed:\", e)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# test_split_edge_cases()\n",
    "# test_ace_edge_cases() \n",
    "# test_rico_edge_cases()\n",
    "# test_general_edge_cases()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "551724db-a07a-40f1-85b6-83a59b5400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTS\n",
    "#get_uniprot_sequence(\"\")  # Empty protein name (should raise ValueError)\n",
    "# get_uniprot_sequence(None)  # None as protein name (should raise ValueError)\n",
    "#get_uniprot_sequence(\"FAKEPROTEINNAME12345\")  # Non-existent protein (should raise ValueError from API response)\n",
    "# additional_sequence_json(\"ACT1\", count=0)  # count is zero (should raise ValueError)\n",
    "# additional_sequence_json(\"ACT1\", count=-5)  # count is negative (should raise ValueError)\n",
    "# additional_sequence_json(\"ACT1\", template=\"yes\")\n",
    "# create_af3_job(\"\", count=1)  # Empty protein name (should raise ValueError)\n",
    "# create_af3_job(\"ACT1\", \"ACT2\", count=[1])  # count list too short (should raise ValueError)\n",
    "# create_af3_job(\"ACT1\", \"ACT2\", count=[1, 0])  # count list contains zero (should raise ValueError)\n",
    "# create_af3_job(\"ACT1\", count=\"one\")  # count is not int or list (should raise ValueError)\n",
    "# create_af3_job(\"ACT1\", name_prefix=123) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
