{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30ab0577-f328-47ec-a6ee-c24cc9123798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from itertools import product\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037cd3f-e54f-40f6-bca2-c5c620c5059d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Outdated Functions\n",
    "These are past versions of the functions below, for safekeeping reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "427498e3-795d-4382-9d53-2bc439b54c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is an alternative to the previous compound function\\nFunction that takes *one single dictionary* with protein names and their respective count/ranges.\\nIt uses the combine_count_ranges() Function and then \\nspits out json-lists with as many jobs as there are dictionaries (output combine function)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function that takes the full sequence and makes a json file out of it\n",
    "\"\"\"\n",
    "\n",
    "# def create_af3_job(sequences, name=\"af3_job\"):\n",
    "#     job = {\n",
    "#         \"name\": name,\n",
    "#         \"version\": 1,\n",
    "#         \"dialect\": \"alphafoldserver\",\n",
    "#         \"sequences\": sequences\n",
    "#     }\n",
    "\n",
    "#     return job\n",
    "\n",
    "# #Example:\n",
    "\n",
    "# sequences = [\n",
    "#     {\"proteinChain\": {\"sequence\": \"mflrsvnravtrsilttpkpavvksswrvftvanskrcftpaaimrnqetqrvgdilqselkieketlpestsldsfndflnkykfslvetpgkneaeivrrtesgetvhvffdvaqianlpynnamdenteqnedgineddfdalsdnfanvnvviskesasepavsfellmnlqegsfyvdsatpypsvdaalnqsaeaeitrelvyhgppfsnldeelqesleaylesrgvneelasfisaysefkenneyiswlekmkkffh\", \"count\": 1, \"useStructureTemplate\": True}}\n",
    "# ]\n",
    "\n",
    "# job = create_af3_job(sequences)\n",
    "\n",
    "# with open(\"job.json\", \"w\") as f:\n",
    "#     json.dump([job], f, indent=2)\n",
    "\n",
    "\"\"\"\n",
    "Create a function which acts as a helper function in future functions, which creates a json file in accordance to AlphaFold requisites\n",
    "\"\"\"\n",
    "# def create_af3_job(protein_name, count = 1, template = True, name_prefix=\"af3_job\"):\n",
    "#     sequence = get_uniprot_sequence(protein_name)\n",
    "#     job = {\n",
    "#         \"name\": f\"{name_prefix}_{protein_name}\",\n",
    "#         \"version\": 1,\n",
    "#         \"dialect\": \"alphafoldserver\",\n",
    "#         \"sequences\": [\n",
    "#             {\n",
    "#                 \"proteinChain\": {\n",
    "#                     \"sequence\" : sequence, #SEQUENCE_VARIABLE\n",
    "#                     \"count\" : count, #COUNT_VARIABLE\n",
    "#                     \"usesStructureTemplate\" : template #STRUCTURE_TEMPLATE_VARIABLE\n",
    "#                 }\n",
    "#             }\n",
    "#         ]\n",
    "#     }\n",
    "#     return job\n",
    "\n",
    "\"\"\"\n",
    "Function that takes multiple protein names and makes json jobs out of it\n",
    "The Output is a json file for AF in list style, so each proteins gets a prediction value \n",
    "\"\"\"\n",
    "# def proteins_to_af3_job(*protein_names, template=True, count=1, name_prefix=\"af3_job\"):\n",
    "\n",
    "#     jobs = []\n",
    "\n",
    "#     for i, name in enumerate(protein_names, start=1):\n",
    "#         sequence = get_uniprot_sequence(name) # use the function defined above\n",
    "#         job = {\n",
    "#             \"name\": f\"{name_prefix}_{name}\",\n",
    "#             \"version\": 1,\n",
    "#             \"dialect\": \"alphafoldserver\",\n",
    "#             \"sequences\": [{\n",
    "#                 \"proteinChain\": {\n",
    "#                     \"sequence\": sequence,\n",
    "#                     \"count\": count,\n",
    "#                     \"useStructureTemplate\": template\n",
    "#                 }\n",
    "#             }]\n",
    "#         }\n",
    "#         jobs.append(job)\n",
    "    \n",
    "#     with open(\"job.json\", \"w\") as f:\n",
    "#         json.dump(jobs, f, indent=2)\n",
    "\n",
    "# Updated Version with helper function:\n",
    "\n",
    "# might replace completely with Handle Count Version\n",
    "\"\"\"\n",
    "Function that takes multiple protein names and makes json jobs out of it\n",
    "The Output is a json file for AF in list style, so each proteins gets a prediction value \n",
    "\"\"\"\n",
    "\n",
    "# def proteins_to_af3_job(*protein_names, template=True, count=1, name_prefix=\"af3_job\"):\n",
    "\n",
    "#     jobs = []\n",
    "\n",
    "#     for i, protein_name in enumerate(protein_names, start=1):\n",
    "#         job = create_af3_job(protein_name, count = count, template = template, name_prefix = name_prefix)\n",
    "#         jobs.append(job)\n",
    "    \n",
    "#     with open(\"job.json\", \"w\") as f:\n",
    "#         json.dump(jobs, f, indent=2) \n",
    "\n",
    "\"\"\"\n",
    "Function that takes multiple protein names and makes json jobs out of it\n",
    "The Output is a json file for AF in list style, so each proteins gets a prediction value, but this time,\n",
    "you can add a *list* of counts to change the number of proteins in the single job\n",
    "\"\"\"\n",
    "\n",
    "# def count_proteins_to_af3_job(*protein_names, template=True, count=1, name_prefix=\"af3_job\"):\n",
    "\n",
    "#     jobs = []\n",
    "\n",
    "#     for i, name in enumerate(protein_names):\n",
    "#         actual_count = count[i] if isinstance(count, list) else count\n",
    "#         sequence = get_uniprot_sequence(name)\n",
    "#         job = {\n",
    "#             \"name\": f\"{name_prefix}_{name}\",\n",
    "#             \"version\": 1,\n",
    "#             \"dialect\": \"alphafoldserver\",\n",
    "#             \"sequences\": [{\n",
    "#                 \"proteinChain\": {\n",
    "#                     \"sequence\": sequence,\n",
    "#                     \"count\":actual_count,\n",
    "#                     \"useStructureTemplate\": template\n",
    "#                 }\n",
    "#             }]\n",
    "#         }\n",
    "#         jobs.append(job)\n",
    "    \n",
    "#     with open(\"job.json\", \"w\") as f:\n",
    "#         json.dump(jobs, f, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function that takes *multiple dictionaries* with protein names and their respective count.\n",
    "spits out a json list with as many jobs as there are dictionaries, and this time\n",
    "every job can entail multiple proteins at the same time!\n",
    "\"\"\"\n",
    "\n",
    "# def single_compounds_af3(*protein_compounds, template = True, name_prefix = \"af3_single_compound_job\"): # protein_compounds are dictionaries\n",
    "\n",
    "#     jobs = []\n",
    "\n",
    "#     for i, protein_compound in enumerate(protein_compounds):\n",
    "#         sequences = []\n",
    "#         for protein_name, count in protein_compound.items():\n",
    "#             sequence = get_uniprot_sequence(protein_name)\n",
    "#             sequences.append({\n",
    "#                 \"proteinChain\": {\n",
    "#                     \"sequence\": sequence,\n",
    "#                     \"count\": count,\n",
    "#                     \"useStructureTemplate\": template\n",
    "#                 }\n",
    "#             })\n",
    "\n",
    "#         job = {\n",
    "#             \"name\": f\"{name_prefix}_{i+1}\", # get more suitable name for jobs !!! make it so it reflects the inputted proteins\n",
    "#             \"version\": 1,\n",
    "#             \"dialect\": \"alphafoldserver\",\n",
    "#             \"sequences\": sequences\n",
    "#         }\n",
    "\n",
    "#         jobs.append(job)\n",
    "\n",
    "#     with open(\"job.json\", \"w\") as f:\n",
    "#         json.dump(jobs, f, indent=2)\n",
    "\n",
    "\"\"\"\n",
    "This is an alternative to the previous compound function\n",
    "Function that takes *one single dictionary* with protein names and their respective count/ranges.\n",
    "It uses the combine_count_ranges() Function and then \n",
    "spits out json-lists with as many jobs as there are dictionaries (output combine function)\n",
    "\"\"\"\n",
    "\n",
    "# Copy last compund function to make it work with lists instead of single arguments\n",
    "# def iterative_compound_af3(range_dictionary, template = True, name_prefix = \"af3_iterative_compound_job\"):\n",
    "\n",
    "#     jobs = []\n",
    "\n",
    "#     protein_compounds = combine_count_ranges(range_dictionary) # is list\n",
    "\n",
    "#     job_num = 1\n",
    "\n",
    "#     for protein_compound in protein_compounds: #is dictionary\n",
    "#         sequences = []\n",
    "#         for protein_name, count in protein_compound.items():\n",
    "#             sequence = get_uniprot_sequence(protein_name)\n",
    "#             sequences.append({\n",
    "#                 \"proteinChain\": {\n",
    "#                     \"sequence\": sequence,\n",
    "#                     \"count\": count,\n",
    "#                     \"useStructureTemplate\": template\n",
    "#                 }\n",
    "#             })\n",
    "\n",
    "#         job = {\n",
    "#             \"name\": f\"{name_prefix}_{job_num}\", \n",
    "#             \"version\": 1,\n",
    "#             \"dialect\": \"alphafoldserver\",\n",
    "#             \"sequences\": sequences\n",
    "#         }\n",
    "\n",
    "#         jobs.append(job)\n",
    "#         job_num += 1\n",
    "\n",
    "#     with open(\"job.json\", \"w\") as f:\n",
    "#         json.dump(jobs, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65550a0e-a33b-4bd6-b95e-ffa8931bdfa7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helper Function: Protein-Sequence request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbfe13b5-2c42-4458-b858-49d2dd49cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that takes the name of a protein as a *string* and gives back the aminoacid sequence through UniProts API\n",
    "\"\"\"\n",
    "\n",
    "def get_uniprot_sequence(protein_name, taxon_id=\"559292\"):\n",
    "    url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    query = f'gene_exact:{protein_name} AND organism_id:{taxon_id}'\n",
    "\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"fasta\", # Wir wollen fasta weil es nices standard-format ist aus dem wir die info gut auslesen koennen\n",
    "        \"size\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200 and response.text.startswith(\">\"): # check rightigen status-code und ob fasta text\n",
    "        lines = response.text.splitlines()\n",
    "        sequence = \"\".join(lines[1:]) # Nur die Sequenz rausholen und in einen string formattieren\n",
    "        return sequence\n",
    "    else:\n",
    "        raise ValueError(f\"No sequence found or request failed for {protein_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a930a48-b8fa-4931-a0b1-21e9e0401c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "#get_uniprot_sequence(\"YB022C\") # is equal to get_uniprot_sequence(\"Pim1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd007239-f1f6-4f12-9ab7-664cae13e50a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helper Function: Jason-Job-File creation\n",
    "\n",
    "Noting right here, that these don't open a json-file just yet, they only return a job string in json format together.\n",
    "When inputting multiple protein names, you get a compound job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbd7758a-df31-4c0b-b418-3a527fd23c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Die Funktion soll dem modularem Aufbau von AlphaStream helfen - es ist eine unterfunktion von create_af3_job und kommt \n",
    "zu Nutzen in den compound_job Funktionen.\n",
    "Input: \n",
    "protein_name : str\n",
    "count : int\n",
    "template : boolean\n",
    "\"\"\"\n",
    "def additional_sequence_json(protein_name, count = 1, template = True):\n",
    "    if not isinstance(count, int) or count < 1:\n",
    "        raise ValueError(f\"count for {protein_name} must be a positive integer\")\n",
    "    if not isinstance(template, bool):\n",
    "        raise ValueError(f\"template parameter for {protein_name} must be a boolean\")\n",
    "    sequence = get_uniprot_sequence(protein_name)\n",
    "    the_additional_sequence = {\"proteinChain\" : {\n",
    "        \"sequence\" : sequence, \n",
    "        \"count\" : count, \n",
    "        \"usesStructureTemplate\" : template}\n",
    "                          }\n",
    "    return the_additional_sequence\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function acts as a helper function in future functions.\n",
    "It returns a json-File in accordance to AlphaFold Server prerequisites.\n",
    "Input :\n",
    "protein_name : one or multiple str\n",
    "count : int or list of ints (MUST be length of *protein_name), or if int and multiple proteins -> int is used for all proteins\n",
    "template : boolean\n",
    "name_prefix : str\n",
    "\"\"\"\n",
    "def create_af3_job(*protein_name, count = 1, template = True, name_prefix=\"af3_job\"): \n",
    "    if len(protein_name) > 1:\n",
    "        if isinstance(count, int):\n",
    "            count = [count] * len(protein_name)\n",
    "        elif len(protein_name) != len(count):\n",
    "            raise ValueError(\"Amount of Proteins must be equal to length of count parameter\") \n",
    "    job = {\n",
    "        \"name\": f\"{name_prefix}_{'_and_'.join(protein_name)}\",\n",
    "        \"version\": 1,\n",
    "        \"dialect\": \"alphafoldserver\",\n",
    "        \"sequences\": []\n",
    "    }\n",
    "    for i, p_name in enumerate(protein_name):\n",
    "        actual_count = count[i] if isinstance(count, list) else count\n",
    "        job[\"sequences\"].append(additional_sequence_json(p_name, count = actual_count, template = template)) #wie ist es mit count und template?\n",
    "    \n",
    "    return job\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0485760b-b2a0-4732-907e-0ee3d96b5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "#create_af3_job(\"Pim1\", \"Pim1\", count = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb2980-16be-4315-aa57-3b2add77a3fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create Jason-Jobs for multiple proteins with an optional count variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "146093a1-7224-4cce-be6d-dbe37f04e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Single Protein Inference Tasker: spit\n",
    "\n",
    "Function that takes one to multiple protein names and makes a list of Jason-Jobs out of it.\n",
    "The Output is a Json-File for AlphaFold in list-style, so each protein gets own prediction.\n",
    "You can add a *list* of counts to change the count for every protein\n",
    "Input:\n",
    "protein_names : one or multiple str\n",
    "count : int OR list, order must be in accordance to protein name order\n",
    "template : boolean\n",
    "name_prefix : str\n",
    "\"\"\"\n",
    "\n",
    "def spit(*protein_names, count = 1, template=True, name_prefix=\"af3_job\"):\n",
    "\n",
    "    if len(protein_names) > 1:\n",
    "        if isinstance(count, int):\n",
    "            count = [count] * len(protein_names)\n",
    "        elif len(protein_names) != len(count):\n",
    "            raise ValueError(\"Amount of Proteins must be equal to length of count parameter\") \n",
    "\n",
    "    jobs = []\n",
    "\n",
    "    for i, protein_name in enumerate(protein_names):\n",
    "        actual_count = count[i] if isinstance(count, list) else count\n",
    "        job = create_af3_job(protein_name, count = actual_count, template = template, name_prefix = name_prefix)\n",
    "        jobs.append(job)\n",
    "        \n",
    "    x = datetime.datetime.now()\n",
    "    \n",
    "    with open(f\"{'_and_'.join(protein_names)}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "        json.dump(jobs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfa24bb1-321f-47e6-90c1-a6037ec98f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spit(\"Pim1\", \"Mrx6\", \"Mrx6\", count = 3) # or more - Syntax Okay?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50e144-d191-428d-996c-2cba827a5b30",
   "metadata": {},
   "source": [
    "# Create x-amount of arbitrary compound Json-Jobs \n",
    "Be minutious with your input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec892821-90b7-487b-9142-337a11b38f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregate of Compound Entities: ace\n",
    "\n",
    "Function that takes one or multiple *dictionaries* with protein names and their respective count.\n",
    "spits out a json-list with as many jobs as there are dictionaries, and this time\n",
    "every job can entail multiple proteins at the same time!\n",
    "Input :\n",
    "protein_compounds : one or multiple dictionaries:\n",
    "    key : str, the protein name\n",
    "    value : int, is count\n",
    "template : boolean\n",
    "name_prefix :  str\n",
    "\"\"\"\n",
    "\n",
    "def ace(*protein_compounds, template = True, name_prefix = \"af3_compound\", name = \"\", ashelper = False): # protein_compounds are dictionaries\n",
    "\n",
    "    jobs = []\n",
    "    name = name\n",
    "\n",
    "    for i, protein_compound in enumerate(protein_compounds):\n",
    "        job = create_af3_job(*protein_compound.keys(), count = list(protein_compound.values()), template = template, name_prefix = f\"{name_prefix}_{i+1}\")\n",
    "        jobs.append(job)\n",
    "        if not ashelper:\n",
    "            if i+1 < len(protein_compounds):\n",
    "                name += \"-\".join(protein_compound.keys()) + \"_and_\"\n",
    "            else:\n",
    "                name += \"-\".join(protein_compound.keys())\n",
    "        \n",
    "\n",
    "    x = datetime.datetime.now()\n",
    "\n",
    "    with open(f\"{name}_{x.strftime(\"%d%b_%H_%M_%S\")}.json\", \"w\") as f:\n",
    "        json.dump(jobs, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26c99c3b-564a-4d4e-8990-8775b36dc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ace({\"Pim1\" : 1, \"fcyx\": 22}, {\"mam33\" : 4, \"Pim1\" : 1}) # Syntax zu schwierig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c7d8f-c107-47a3-b092-7f7ba1b4d187",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Helper Function: Cartesian-Product for protein ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dc067ce-805e-4d66-b029-17d960380331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that takes one single dictionary with protein names and their respective count, but this time,\n",
    "the count can be a range.\n",
    "It spits out a list of dictionaries with all possible combinations of the given ranges.\n",
    "Its output it supposed to work as an input for the compound function: it's a *list*\n",
    "Input :\n",
    "protein_counts : dictionary:\n",
    "    key : str, protein name\n",
    "    value : int or range, the counts\n",
    "\"\"\"\n",
    "\n",
    "# CHATGPT FOR THE WIN - this gives back a list with dictionaries in all combinations of the given ranges\n",
    "\n",
    "def combine_count_ranges(protein_counts):\n",
    "    # Step 1: Normalize all values to lists\n",
    "    normalized = {k: (v if isinstance(v, range) or isinstance(v, list) else [v]) for k, v in protein_counts.items()}\n",
    "\n",
    "    # Step 2: Separate keys by how many values they have\n",
    "    multi_keys = [k for k, v in normalized.items() if len(v) > 1]\n",
    "    fixed_keys = {k: v[0] for k, v in normalized.items() if len(v) == 1}\n",
    "\n",
    "    # Step 3: Create product of variable value combinations\n",
    "    combinations = product(*(normalized[k] for k in multi_keys))\n",
    "\n",
    "    # Step 4: Rebuild job dicts\n",
    "    job_inputs = []\n",
    "    for combo in combinations:\n",
    "        job = {**fixed_keys}\n",
    "        job.update(dict(zip(multi_keys, combo)))\n",
    "        job_inputs.append(job)\n",
    "\n",
    "    return job_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb487871-370e-45e7-8c3a-e4cd9743389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Pim1': 2, 'Fcyx': 4, 'Mrx6': 3},\n",
       " {'Pim1': 2, 'Fcyx': 4, 'Mrx6': 4},\n",
       " {'Pim1': 2, 'Fcyx': 5, 'Mrx6': 3},\n",
       " {'Pim1': 2, 'Fcyx': 5, 'Mrx6': 4},\n",
       " {'Pim1': 2, 'Fcyx': 6, 'Mrx6': 3},\n",
       " {'Pim1': 2, 'Fcyx': 6, 'Mrx6': 4},\n",
       " {'Pim1': 3, 'Fcyx': 4, 'Mrx6': 3},\n",
       " {'Pim1': 3, 'Fcyx': 4, 'Mrx6': 4},\n",
       " {'Pim1': 3, 'Fcyx': 5, 'Mrx6': 3},\n",
       " {'Pim1': 3, 'Fcyx': 5, 'Mrx6': 4},\n",
       " {'Pim1': 3, 'Fcyx': 6, 'Mrx6': 3},\n",
       " {'Pim1': 3, 'Fcyx': 6, 'Mrx6': 4},\n",
       " {'Pim1': 4, 'Fcyx': 4, 'Mrx6': 3},\n",
       " {'Pim1': 4, 'Fcyx': 4, 'Mrx6': 4},\n",
       " {'Pim1': 4, 'Fcyx': 5, 'Mrx6': 3},\n",
       " {'Pim1': 4, 'Fcyx': 5, 'Mrx6': 4},\n",
       " {'Pim1': 4, 'Fcyx': 6, 'Mrx6': 3},\n",
       " {'Pim1': 4, 'Fcyx': 6, 'Mrx6': 4}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does its input look like: dictionaries with ranges\n",
    "\n",
    "input_dict = {\n",
    "    \"Pim1\": range(2,5),\n",
    "    \"Fcyx\": range(4, 7),\n",
    "    \"Mrx6\": range(3,5)\n",
    "}\n",
    "\n",
    "tryout = combine_count_ranges(input_dict)\n",
    "tryout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415636e-379e-41dd-a3d0-b71697c67e18",
   "metadata": {},
   "source": [
    "# Create compound Json-Jobs with ranges \n",
    "Note the diff to previous compound function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0aaec6f4-0875-4dc8-a140-b62321e459e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run Iterative Combination Operation: rico\n",
    "\n",
    "This is an alternative to the previous compound function.\n",
    "Function that takes *one single dictionary* with protein names and their respective count/ranges.\n",
    "It uses the combine_count_ranges() function and then \n",
    "spits out a json-list with as many jobs as there are dictionaries (the output of combine function)\n",
    "Input :\n",
    "range_dictionary : same as for combine_count_ranges\n",
    "template: boolean\n",
    "name_prefix : str\n",
    "\"\"\"\n",
    "\n",
    "# Copy last compund function to make it work with lists instead of single arguments\n",
    "def rico(range_dictionary, template = True, name_prefix = \"af3_iterative_compound\"):\n",
    "\n",
    "    protein_compounds = combine_count_ranges(range_dictionary) # is list\n",
    "\n",
    "    name = \"ranges_for_\" + \"_\".join(range_dictionary.keys())\n",
    "\n",
    "    ace(*protein_compounds, template = template, name_prefix = name_prefix, name = name, ashelper = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a97ed47-79a9-49e4-99c3-813e598e583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rico(\n",
    "    {\n",
    "    \"Pim1\": range(2,5),\n",
    "    \"Fcyx\": range(1, 2)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399ae61-a634-4621-9745-3416a33931c4",
   "metadata": {},
   "source": [
    "# Zusammenfassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8e41ff3-d9ce-4422-b8c9-5cd650c4a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Sequence *helper function*\n",
    "# get_uniprot_sequence() # Try mistake\n",
    "\n",
    "# # Get Protein Jobs\n",
    "# proteins_to_af3_job()\n",
    "# count_proteins_to_af3_job()\n",
    "\n",
    "# # Compound jobs\n",
    "# single_compounds_af3({\"Pim1\" : 1, \"fcyx\": 2}, {\"mam33\" : 4, \"ATP11\" : 1})\n",
    "\n",
    "# # Combine Ranges *helper function*\n",
    "# input_dict = {}\n",
    "# combine_count_ranges(input_dict)\n",
    "\n",
    "# # better compound job\n",
    "# iterative_compound_af3(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc03558e-0cf2-4eca-9ceb-bd781eda1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create ligand, ion implementation, not that urgent\n",
    "# need to mnake code accessible to osmanlab, urgent, but these steps are necessarz first:\n",
    "# have functional code ready and then put it on the v0 website - question, can I access and work on the website easily?\n",
    "# - update: they use jupyter lab as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddd38364-0b33-4b07-a522-9baa55236438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a python script on command line for Osman Lab - they use Jupyter Lab - but! : as soon as ALPHAFOLD runs locally, comman line\n",
    "# usage will be necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "551724db-a07a-40f1-85b6-83a59b5400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTS\n",
    "#get_uniprot_sequence(\"\")  # Empty protein name (should raise ValueError)\n",
    "#get_uniprot_sequence(None)  # None as protein name (should raise ValueError)\n",
    "#get_uniprot_sequence(\"FAKEPROTEINNAME12345\")  # Non-existent protein (should raise ValueError from API response)\n",
    "#additional_sequence_json(\"ACT1\", count=0)  # count is zero (should raise ValueError)\n",
    "#additional_sequence_json(\"ACT1\", count=-5)  # count is negative (should raise ValueError)\n",
    "#additional_sequence_json(\"ACT1\", template=\"yes\")\n",
    "#create_af3_job(\"\", count=1)  # Empty protein name (should raise ValueError)\n",
    "#create_af3_job(\"ACT1\", \"ACT2\", count=[1])  # count list too short (should raise ValueError)\n",
    "#create_af3_job(\"ACT1\", \"ACT2\", count=[1, 0])  # count list contains zero (should raise ValueError)\n",
    "#create_af3_job(\"ACT1\", count=\"one\")  # count is not int or list (should raise ValueError)\n",
    "#create_af3_job(\"ACT1\", name_prefix=123) \n",
    "\n",
    "#count_proteins_to_af3_job(\"ACT1\", \"ACT2\", count=[1])  # count list too short (should raise ValueError)\n",
    "#count_proteins_to_af3_job(\"ACT1\", \"ACT2\", count=[1, 2, 3])  # count list too long (should raise ValueError)\n",
    "#count_proteins_to_af3_job(\"\", count=1)  # Empty protein name (should raise ValueError)\n",
    "#count_proteins_to_af3_job(\"ACT1\", count=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
